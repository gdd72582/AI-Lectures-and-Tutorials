{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqSsoKz5At7w"
      },
      "source": [
        "# How the order of BatchNorm and Activation affects performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Objective:**  \n",
        "This experiment investigates how the order of BatchNorm and Activation affects performance.\n",
        "\n",
        "**Conditions:**  \n",
        "- Implement three networks with the following structures:\n",
        "  1) Conv (or FC) → BatchNorm → ReLU  \n",
        "  2) Conv (or FC) → ReLU → BatchNorm  \n",
        "  3) Conv (or FC) → LeakyReLU → BatchNorm  \n",
        "- Each network should have 8 blocks\n",
        "\n",
        "**Expected Outcome:**  \n",
        "- No predefined “correct” result; analyze and explain observed performance differences  \n",
        "- A convincing analysis is required regardless of whether the result matches expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Theoretical Background\n",
        "\n",
        "In deep learning, the order of Batch Normalization (BN) and activation functions (e.g., ReLU) within a neural network layer can significantly influence the training dynamics and final performance. Conventionally, BN is applied before the activation (i.e., `Conv → BN → ReLU`). This ordering stabilizes the input distribution to the nonlinearity, potentially enhancing gradient flow.\n",
        "\n",
        "However, the impact of altering this order—such as placing BN after the activation (`Conv → ReLU → BN`) or combining BN with alternative activations like LeakyReLU—remains a topic of empirical interest. Differences in gradient propagation, representational capacity, and learning stability can emerge depending on this sequence.\n",
        "\n",
        "This experiment aims to investigate how such ordering affects not only performance (in terms of accuracy) but also stability (variance across runs) and generalization (consistency across architectures)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Setup\n",
        "\n",
        "- **Architectures Tested**:\n",
        "  - Multi-Layer Perceptron (MLP)\n",
        "  - Convolutional Neural Network (CNN)\n",
        "\n",
        "- **Block Definition** (repeated 5 times per model):\n",
        "  - Structure 1: `Layer → BatchNorm → ReLU`\n",
        "  - Structure 2: `Layer → ReLU → BatchNorm`\n",
        "  - Structure 3: `Layer → LeakyReLU → BatchNorm`\n",
        "\n",
        "- **Evaluation Metrics**:\n",
        "  - **Performance**: Top-1 accuracy on test set\n",
        "  - **Stability**: Mean and standard deviation over 5 independent runs\n",
        "  - **Generalization**: Comparison of patterns across MLP and CNN\n",
        "\n",
        "- **Dataset**: CIFAR-10\n",
        "- **Optimizer**: Adam\n",
        "- **Epochs**: 10\n",
        "- **Batch Size**: 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5KLHDg2eKJAb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qmnz6GHAt71"
      },
      "source": [
        "## Define Three Cases for the Basic Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6hYDZar3KKxC"
      },
      "outputs": [],
      "source": [
        "class Case1Block(nn.Module):\n",
        "    \"\"\"Conv -> BatchNorm -> ReLU\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "class Case2Block(nn.Module):\n",
        "    \"\"\"Conv -> ReLU -> BatchNorm\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bn(self.relu(self.conv(x)))\n",
        "\n",
        "class Case3Block(nn.Module):\n",
        "    \"\"\"Conv -> LeakyReLU -> BatchNorm\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.act = nn.LeakyReLU()\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bn(self.act(self.conv(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvjqs8rXAt71"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BW8wpuwTKOP_"
      },
      "outputs": [],
      "source": [
        "class CNNNetwork(nn.Module):\n",
        "    def __init__(self, block_type='case1', num_blocks=8):\n",
        "        super().__init__()\n",
        "        if block_type == 'case1':\n",
        "            block = Case1Block\n",
        "        elif block_type == 'case2':\n",
        "            block = Case2Block\n",
        "        else :\n",
        "            block = Case3Block\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.blocks = nn.Sequential(*[block(64, 64) for _ in range(num_blocks)])\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DBoL1lgAt72"
      },
      "source": [
        "## Train, Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IQ6DS1sZKSHt"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    correct, total, loss_sum = 0, 0, 0.0\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_sum += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return loss_sum / len(loader), 100. * correct / total\n",
        "\n",
        "# eval\n",
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    correct, total, loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum += loss.item()\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return loss_sum / len(loader), 100. * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ikci0G7KGRDu"
      },
      "outputs": [],
      "source": [
        "def run_experiment(block_type, num_blocks, device, train_loader, test_loader, num_epochs, lr):\n",
        "    model = CNNNetwork(block_type=block_type, num_blocks=num_blocks).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "        test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "        best_test_acc = max(best_test_acc, test_acc)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | Test Acc: {test_acc:.2f}%\")\n",
        "    return best_test_acc\n",
        "\n",
        "def repeat_experiment(block_type, num_blocks, repeat, device, train_loader, test_loader, num_epochs, lr):\n",
        "    accs = []\n",
        "    print(f\"\\n[Experiment] {block_type.upper()} - {repeat} times\\n\")\n",
        "\n",
        "    for run in range(repeat):\n",
        "        print(f\"[{block_type}] Run {run+1}/{repeat}\")\n",
        "        model = CNNNetwork(block_type=block_type, num_blocks=num_blocks).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "            test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "            print(f\"\\tEpoch {epoch+1}/{num_epochs} | Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "        accs.append(test_acc)\n",
        "\n",
        "    mean_acc = np.mean(accs)\n",
        "    std_acc = np.std(accs)\n",
        "    print(f\"\\n {block_type.upper()} result: average Test Acc = {mean_acc:.2f}%, std = {std_acc:.2f}%\\n\")\n",
        "    return mean_acc, std_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev-PYVeUI9Jr",
        "outputId": "81e3d0a3-a7f3-499b-cb91-fc136c3a21b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 76.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==== 실험 5회 반복 - 평균과 표준편차 ====\n",
            "\n",
            "[실험] CASE1 - 5회 반복\n",
            "\n",
            "[case1] Run 1/5\n",
            "\tEpoch 1/10 | Test Acc: 55.42%\n",
            "\tEpoch 2/10 | Test Acc: 58.55%\n",
            "\tEpoch 3/10 | Test Acc: 66.91%\n",
            "\tEpoch 4/10 | Test Acc: 66.51%\n",
            "\tEpoch 5/10 | Test Acc: 71.23%\n",
            "\tEpoch 6/10 | Test Acc: 68.95%\n",
            "\tEpoch 7/10 | Test Acc: 75.48%\n",
            "\tEpoch 8/10 | Test Acc: 74.47%\n",
            "\tEpoch 9/10 | Test Acc: 77.94%\n",
            "\tEpoch 10/10 | Test Acc: 71.78%\n",
            "[case1] Run 2/5\n",
            "\tEpoch 1/10 | Test Acc: 53.30%\n",
            "\tEpoch 2/10 | Test Acc: 54.39%\n",
            "\tEpoch 3/10 | Test Acc: 59.88%\n",
            "\tEpoch 4/10 | Test Acc: 69.44%\n",
            "\tEpoch 5/10 | Test Acc: 69.20%\n",
            "\tEpoch 6/10 | Test Acc: 73.15%\n",
            "\tEpoch 7/10 | Test Acc: 73.24%\n",
            "\tEpoch 8/10 | Test Acc: 78.16%\n",
            "\tEpoch 9/10 | Test Acc: 75.87%\n",
            "\tEpoch 10/10 | Test Acc: 76.14%\n",
            "[case1] Run 3/5\n",
            "\tEpoch 1/10 | Test Acc: 45.12%\n",
            "\tEpoch 2/10 | Test Acc: 63.17%\n",
            "\tEpoch 3/10 | Test Acc: 69.20%\n",
            "\tEpoch 4/10 | Test Acc: 63.68%\n",
            "\tEpoch 5/10 | Test Acc: 71.95%\n",
            "\tEpoch 6/10 | Test Acc: 75.72%\n",
            "\tEpoch 7/10 | Test Acc: 79.22%\n",
            "\tEpoch 8/10 | Test Acc: 73.29%\n",
            "\tEpoch 9/10 | Test Acc: 78.25%\n",
            "\tEpoch 10/10 | Test Acc: 78.37%\n",
            "[case1] Run 4/5\n",
            "\tEpoch 1/10 | Test Acc: 53.23%\n",
            "\tEpoch 2/10 | Test Acc: 61.08%\n",
            "\tEpoch 3/10 | Test Acc: 66.93%\n",
            "\tEpoch 4/10 | Test Acc: 69.38%\n",
            "\tEpoch 5/10 | Test Acc: 70.29%\n",
            "\tEpoch 6/10 | Test Acc: 72.04%\n",
            "\tEpoch 7/10 | Test Acc: 73.40%\n",
            "\tEpoch 8/10 | Test Acc: 75.02%\n",
            "\tEpoch 9/10 | Test Acc: 78.78%\n",
            "\tEpoch 10/10 | Test Acc: 76.99%\n",
            "[case1] Run 5/5\n",
            "\tEpoch 1/10 | Test Acc: 45.28%\n",
            "\tEpoch 2/10 | Test Acc: 53.32%\n",
            "\tEpoch 3/10 | Test Acc: 66.29%\n",
            "\tEpoch 4/10 | Test Acc: 69.64%\n",
            "\tEpoch 5/10 | Test Acc: 62.46%\n",
            "\tEpoch 6/10 | Test Acc: 76.72%\n",
            "\tEpoch 7/10 | Test Acc: 75.31%\n",
            "\tEpoch 8/10 | Test Acc: 79.34%\n",
            "\tEpoch 9/10 | Test Acc: 76.13%\n",
            "\tEpoch 10/10 | Test Acc: 74.41%\n",
            "\n",
            " CASE1 결과 요약: 평균 Test Acc = 75.54%, 표준편차 = 2.28%\n",
            "\n",
            "\n",
            "[실험] CASE2 - 5회 반복\n",
            "\n",
            "[case2] Run 1/5\n",
            "\tEpoch 1/10 | Test Acc: 56.63%\n",
            "\tEpoch 2/10 | Test Acc: 66.84%\n",
            "\tEpoch 3/10 | Test Acc: 69.81%\n",
            "\tEpoch 4/10 | Test Acc: 73.00%\n",
            "\tEpoch 5/10 | Test Acc: 75.57%\n",
            "\tEpoch 6/10 | Test Acc: 77.32%\n",
            "\tEpoch 7/10 | Test Acc: 76.70%\n",
            "\tEpoch 8/10 | Test Acc: 79.19%\n",
            "\tEpoch 9/10 | Test Acc: 80.73%\n",
            "\tEpoch 10/10 | Test Acc: 81.28%\n",
            "[case2] Run 2/5\n",
            "\tEpoch 1/10 | Test Acc: 59.68%\n",
            "\tEpoch 2/10 | Test Acc: 63.91%\n",
            "\tEpoch 3/10 | Test Acc: 69.70%\n",
            "\tEpoch 4/10 | Test Acc: 73.96%\n",
            "\tEpoch 5/10 | Test Acc: 77.68%\n",
            "\tEpoch 6/10 | Test Acc: 79.91%\n",
            "\tEpoch 7/10 | Test Acc: 80.75%\n",
            "\tEpoch 8/10 | Test Acc: 80.13%\n",
            "\tEpoch 9/10 | Test Acc: 80.83%\n",
            "\tEpoch 10/10 | Test Acc: 81.63%\n",
            "[case2] Run 3/5\n",
            "\tEpoch 1/10 | Test Acc: 54.93%\n",
            "\tEpoch 2/10 | Test Acc: 65.23%\n",
            "\tEpoch 3/10 | Test Acc: 70.18%\n",
            "\tEpoch 4/10 | Test Acc: 71.74%\n",
            "\tEpoch 5/10 | Test Acc: 73.36%\n",
            "\tEpoch 6/10 | Test Acc: 77.36%\n",
            "\tEpoch 7/10 | Test Acc: 78.17%\n",
            "\tEpoch 8/10 | Test Acc: 79.96%\n",
            "\tEpoch 9/10 | Test Acc: 77.71%\n",
            "\tEpoch 10/10 | Test Acc: 79.43%\n",
            "[case2] Run 4/5\n",
            "\tEpoch 1/10 | Test Acc: 49.17%\n",
            "\tEpoch 2/10 | Test Acc: 64.52%\n",
            "\tEpoch 3/10 | Test Acc: 69.91%\n",
            "\tEpoch 4/10 | Test Acc: 71.78%\n",
            "\tEpoch 5/10 | Test Acc: 74.99%\n",
            "\tEpoch 6/10 | Test Acc: 77.58%\n",
            "\tEpoch 7/10 | Test Acc: 78.60%\n",
            "\tEpoch 8/10 | Test Acc: 78.65%\n",
            "\tEpoch 9/10 | Test Acc: 80.93%\n",
            "\tEpoch 10/10 | Test Acc: 80.94%\n",
            "[case2] Run 5/5\n",
            "\tEpoch 1/10 | Test Acc: 57.04%\n",
            "\tEpoch 2/10 | Test Acc: 66.21%\n",
            "\tEpoch 3/10 | Test Acc: 68.80%\n",
            "\tEpoch 4/10 | Test Acc: 72.88%\n",
            "\tEpoch 5/10 | Test Acc: 75.70%\n",
            "\tEpoch 6/10 | Test Acc: 77.87%\n",
            "\tEpoch 7/10 | Test Acc: 79.60%\n",
            "\tEpoch 8/10 | Test Acc: 80.87%\n",
            "\tEpoch 9/10 | Test Acc: 80.22%\n",
            "\tEpoch 10/10 | Test Acc: 81.28%\n",
            "\n",
            " CASE2 결과 요약: 평균 Test Acc = 80.91%, 표준편차 = 0.77%\n",
            "\n",
            "\n",
            "[실험] CASE3 - 5회 반복\n",
            "\n",
            "[case3] Run 1/5\n",
            "\tEpoch 1/10 | Test Acc: 55.72%\n",
            "\tEpoch 2/10 | Test Acc: 64.06%\n",
            "\tEpoch 3/10 | Test Acc: 69.33%\n",
            "\tEpoch 4/10 | Test Acc: 73.02%\n",
            "\tEpoch 5/10 | Test Acc: 75.44%\n",
            "\tEpoch 6/10 | Test Acc: 77.59%\n",
            "\tEpoch 7/10 | Test Acc: 78.82%\n",
            "\tEpoch 8/10 | Test Acc: 79.92%\n",
            "\tEpoch 9/10 | Test Acc: 80.14%\n",
            "\tEpoch 10/10 | Test Acc: 80.53%\n",
            "[case3] Run 2/5\n",
            "\tEpoch 1/10 | Test Acc: 57.06%\n",
            "\tEpoch 2/10 | Test Acc: 63.92%\n",
            "\tEpoch 3/10 | Test Acc: 69.88%\n",
            "\tEpoch 4/10 | Test Acc: 74.21%\n",
            "\tEpoch 5/10 | Test Acc: 77.74%\n",
            "\tEpoch 6/10 | Test Acc: 78.11%\n",
            "\tEpoch 7/10 | Test Acc: 79.54%\n",
            "\tEpoch 8/10 | Test Acc: 79.98%\n",
            "\tEpoch 9/10 | Test Acc: 82.07%\n",
            "\tEpoch 10/10 | Test Acc: 82.14%\n",
            "[case3] Run 3/5\n",
            "\tEpoch 1/10 | Test Acc: 55.47%\n",
            "\tEpoch 2/10 | Test Acc: 66.16%\n",
            "\tEpoch 3/10 | Test Acc: 70.25%\n",
            "\tEpoch 4/10 | Test Acc: 74.42%\n",
            "\tEpoch 5/10 | Test Acc: 76.16%\n",
            "\tEpoch 6/10 | Test Acc: 79.91%\n",
            "\tEpoch 7/10 | Test Acc: 80.28%\n",
            "\tEpoch 8/10 | Test Acc: 81.24%\n",
            "\tEpoch 9/10 | Test Acc: 82.06%\n",
            "\tEpoch 10/10 | Test Acc: 83.25%\n",
            "[case3] Run 4/5\n",
            "\tEpoch 1/10 | Test Acc: 56.72%\n",
            "\tEpoch 2/10 | Test Acc: 63.99%\n",
            "\tEpoch 3/10 | Test Acc: 70.57%\n",
            "\tEpoch 4/10 | Test Acc: 72.68%\n",
            "\tEpoch 5/10 | Test Acc: 74.26%\n",
            "\tEpoch 6/10 | Test Acc: 77.90%\n",
            "\tEpoch 7/10 | Test Acc: 78.42%\n",
            "\tEpoch 8/10 | Test Acc: 78.94%\n",
            "\tEpoch 9/10 | Test Acc: 79.87%\n",
            "\tEpoch 10/10 | Test Acc: 81.33%\n",
            "[case3] Run 5/5\n",
            "\tEpoch 1/10 | Test Acc: 49.53%\n",
            "\tEpoch 2/10 | Test Acc: 63.22%\n",
            "\tEpoch 3/10 | Test Acc: 68.80%\n",
            "\tEpoch 4/10 | Test Acc: 72.60%\n",
            "\tEpoch 5/10 | Test Acc: 75.32%\n",
            "\tEpoch 6/10 | Test Acc: 77.99%\n",
            "\tEpoch 7/10 | Test Acc: 77.94%\n",
            "\tEpoch 8/10 | Test Acc: 81.39%\n",
            "\tEpoch 9/10 | Test Acc: 80.55%\n",
            "\tEpoch 10/10 | Test Acc: 81.40%\n",
            "\n",
            " CASE3 결과 요약: 평균 Test Acc = 81.73%, 표준편차 = 0.92%\n",
            "\n",
            "\n",
            "=== 최종 결과 요약 ===\n",
            "CASE1  : 평균 Test Accuracy = 75.54% ± 2.28%\n",
            "CASE2  : 평균 Test Accuracy = 80.91% ± 0.77%\n",
            "CASE3  : 평균 Test Accuracy = 81.73% ± 0.92%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"\\n==== Experiment 5 times ====\")\n",
        "results = {}\n",
        "\n",
        "for case in ['case1', 'case2', 'case3']:\n",
        "    mean_acc, std_acc = repeat_experiment(case, num_blocks=8, repeat=5, device=device,\n",
        "                                          train_loader=train_loader, test_loader=test_loader,\n",
        "                                          num_epochs=10, lr=0.001)\n",
        "    results[case] = (mean_acc, std_acc)\n",
        "\n",
        "print(\"\\n=== Summary of Results ===\")\n",
        "for case, (mean, std) in results.items():\n",
        "    print(f\"{case.upper():<6} : average Test Accuracy = {mean:.2f}% ± {std:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result - Experimet1\n",
        "\n",
        "|  | 평균 Test Accuracy (%) | 표준편차 (%) |\n",
        "| --- | --- | --- |\n",
        "| CASE1 | 75.5 | ± 2.28 |\n",
        "| CASE2 | 80.91 | ± 0.77 |\n",
        "| CASE3 | 81.73 | ± 0.92 |\n",
        "\n",
        "- test acc : Case 1 < case 2 < case3\n",
        "- std : case1 < case3 < case2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNpNDN9BLRgR"
      },
      "source": [
        "## Experiment 2 — Generalization Across Architectures\n",
        "\n",
        "This experiment aims to assess the generality of the observed effects regarding the ordering of activation functions and batch normalization layers. Specifically, we investigate whether the trends observed in performance and stability are consistent across different network architectures.\n",
        "\n",
        "To this end, we conduct parallel experiments on two distinct model types:\n",
        "- A **Multi-Layer Perceptron (MLP)**, representing a fully connected feedforward network\n",
        "- A **Convolutional Neural Network (CNN)**, representing spatial feature-based architectures\n",
        "\n",
        "### Research Question\n",
        "> Does altering the sequence of batch normalization and activation layers lead to similar outcomes in both MLP and CNN architectures, in terms of performance trends and training stability?\n",
        "\n",
        "By comparing these two structurally different models under identical experimental conditions, we aim to determine the extent to which the effect of layer ordering generalizes across architectural paradigms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7V4NWWLMasa"
      },
      "source": [
        "### MLP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "chfgmOaKMZq6"
      },
      "outputs": [],
      "source": [
        "class MLPNetwork(nn.Module):\n",
        "    def __init__(self, block_type):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        if block_type == 'case1':\n",
        "            act1 = nn.Sequential(nn.Linear(3*32*32, 512), nn.BatchNorm1d(512), nn.ReLU())\n",
        "        elif block_type == 'case2':\n",
        "            act1 = nn.Sequential(nn.Linear(3*32*32, 512), nn.ReLU(), nn.BatchNorm1d(512))\n",
        "        else :\n",
        "            act1 = nn.Sequential(nn.Linear(3*32*32, 512), nn.LeakyReLU(), nn.BatchNorm1d(512))\n",
        "\n",
        "        # 여러 층 쌓기\n",
        "        self.mlp = nn.Sequential(\n",
        "            act1,\n",
        "            nn.Linear(512, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.mlp(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QR-L9uDaLOK_"
      },
      "outputs": [],
      "source": [
        "def run_experiment(model_type='cnn', block_type='case1', num_blocks=8,\n",
        "                   epochs=10, batch_size=128, lr=0.001, repeat=5, device='cpu'):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc_list = []\n",
        "    for r in range(repeat):\n",
        "        # select model\n",
        "        if model_type == 'cnn':\n",
        "            model = CNNNetwork(block_type, num_blocks).to(device)\n",
        "        elif model_type == 'mlp':\n",
        "            model = MLPNetwork(block_type).to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "            test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "\n",
        "        acc_list.append(test_acc)\n",
        "        print(f\"{model_type.upper()} {block_type.upper()} Run {r+1}: {test_acc:.2f}%\")\n",
        "\n",
        "    acc_array = np.array(acc_list)\n",
        "    return acc_array.mean(), acc_array.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IkUbtx_L3R_",
        "outputId": "66dd9f8f-2aaa-4e84-ad2d-f0d02dae93af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " CNN Results:\n",
            "CNN CASE1 Run 1: 80.59%\n",
            "CNN CASE1 Run 2: 77.32%\n",
            "CNN CASE1 Run 3: 76.81%\n",
            "CNN CASE1 Run 4: 78.24%\n",
            "CNN CASE1 Run 5: 80.74%\n",
            "CASE1 : 78.74% ± 1.64%\n",
            "CNN CASE2 Run 1: 80.21%\n",
            "CNN CASE2 Run 2: 80.65%\n",
            "CNN CASE2 Run 3: 81.83%\n",
            "CNN CASE2 Run 4: 79.96%\n",
            "CNN CASE2 Run 5: 80.90%\n",
            "CASE2 : 80.71% ± 0.65%\n",
            "CNN CASE3 Run 1: 81.42%\n",
            "CNN CASE3 Run 2: 80.91%\n",
            "CNN CASE3 Run 3: 81.55%\n",
            "CNN CASE3 Run 4: 80.46%\n",
            "CNN CASE3 Run 5: 79.82%\n",
            "CASE3 : 80.83% ± 0.64%\n",
            "\n",
            " MLP Results:\n",
            "MLP CASE1 Run 1: 56.60%\n",
            "MLP CASE1 Run 2: 56.05%\n",
            "MLP CASE1 Run 3: 55.43%\n",
            "MLP CASE1 Run 4: 55.45%\n",
            "MLP CASE1 Run 5: 55.36%\n",
            "CASE1 : 55.78% ± 0.48%\n",
            "MLP CASE2 Run 1: 55.50%\n",
            "MLP CASE2 Run 2: 55.73%\n",
            "MLP CASE2 Run 3: 55.27%\n",
            "MLP CASE2 Run 4: 56.02%\n",
            "MLP CASE2 Run 5: 55.82%\n",
            "CASE2 : 55.67% ± 0.26%\n",
            "MLP CASE3 Run 1: 55.07%\n",
            "MLP CASE3 Run 2: 55.72%\n",
            "MLP CASE3 Run 3: 56.24%\n",
            "MLP CASE3 Run 4: 55.25%\n",
            "MLP CASE3 Run 5: 56.25%\n",
            "CASE3 : 55.71% ± 0.49%\n"
          ]
        }
      ],
      "source": [
        "for model_type in ['cnn', 'mlp']:\n",
        "    print(f\"\\n {model_type.upper()} Results:\")\n",
        "    for block_type in ['case1', 'case2', 'case3']:\n",
        "        mean_acc, std_acc = run_experiment(model_type=model_type, block_type=block_type, device=device)\n",
        "        print(f\"{block_type.upper()} : {mean_acc:.2f}% ± {std_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result - Experiment 2\n",
        "\n",
        "| **Model** | **Case** | **Run 1** | **Run 2** | **Run 3** | **Run 4** | **Run 5** | **Mean (%)** | **Std (%)** |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| CNN | CASE1 | 80.59% | 77.32% | 76.81% | 78.24% | 80.74% | **78.74** | **1.64** |\n",
        "| CNN | CASE2 | 80.21% | 80.65% | 81.83% | 79.96% | 80.90% | **80.71** | **0.65** |\n",
        "| CNN | CASE3 | 81.42% | 80.91% | 81.55% | 80.46% | 79.82% | **80.83** | **0.64** |\n",
        "| MLP | CASE1 | 56.60% | 56.05% | 55.43% | 55.45% | 55.36% | **55.78** | **0.48** |\n",
        "| MLP | CASE2 | 55.50% | 55.73% | 55.27% | 56.02% | 55.82% | **55.67** | **0.26** |\n",
        "| MLP | CASE3 | 55.07% | 55.72% | 56.24% | 55.25% | 56.25% | **55.71** | **0.49** |\n",
        "\n",
        "**Based on performance (Test Accuracy):**\n",
        "- In the CNN architecture: CASE 3 > CASE 2 > CASE 1\n",
        "- In the MLP architecture: CASE 1 ≈ CASE 3 ≈ CASE 2 (differences are negligible)\n",
        "\n",
        "**Based on stability (Standard Deviation):**\n",
        "- CNN: CASE 3 ≈ CASE 2 < CASE 1\n",
        "- MLP: All three cases exhibit low variance, with no significant difference observed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n",
        "\n",
        "### Interpretation Based on Performance Metrics\n",
        "- **CASE 1** (`Conv → BN → ReLU`) consistently yielded the lowest accuracy among the three configurations. This may be attributed to the reduced nonlinearity introduced after batch normalization, potentially limiting the representational power of the network.\n",
        "- Both **CASE 2** and **CASE 3** achieved higher test accuracy. This suggests that applying Batch Normalization after the activation function may enhance nonlinearity and improve learning dynamics.\n",
        "- Notably, **CASE 3**, which employs LeakyReLU followed by BatchNorm, outperformed the others. The slight preservation of negative gradients by LeakyReLU likely contributed to a performance gain of approximately 0.82%.\n",
        "\n",
        "### Interpretation Based on Training Stability\n",
        "- In the CNN architecture, **CASE 2** and **CASE 3** exhibited lower standard deviation compared to **CASE 1**, indicating more consistent convergence across runs.\n",
        "- This may be explained by the fact that when BatchNorm is applied after the activation, the activation outputs are normalized, which stabilizes gradient flow and leads to reduced variability between experiments.\n",
        "\n",
        "### Architectural Differences\n",
        "- In the MLP architecture, all three configurations showed negligible differences in performance. This may be due to the nature of MLPs, which process fixed-size vector inputs and are less sensitive to the activation-BN ordering.\n",
        "- Although the MLP results exhibited low variance overall, their absolute accuracy was lower than CNNs, suggesting that the model may have been less responsive to the structural variations under the given experimental conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In the CNN architecture, **CASE 3** (`LeakyReLU → BatchNorm`) yielded the highest performance, with **CASE 2** (`ReLU → BatchNorm`) performing slightly lower but still superior to the conventional approach.\n",
        "\n",
        "In contrast, the MLP architecture showed minimal sensitivity to the ordering of activation and normalization layers, with negligible differences observed across all configurations.\n",
        "\n",
        "Notably, **CASE 2** (`ReLU → BatchNorm`) consistently outperformed the widely adopted **CASE 1** (`BatchNorm → ReLU`) in terms of both accuracy and stability (as measured by standard deviation). These findings suggest that the placement of normalization relative to the activation function should not be considered a fixed design convention. Instead, it should be treated as a tunable architectural choice that warrants empirical evaluation, particularly in convolutional models where its impact may be more pronounced."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
